{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-21T08:19:48.238743Z",
     "start_time": "2024-12-21T08:19:06.249375Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 定义函数\n",
    "# define function\n",
    "def f(x):\n",
    "    return x**3 + 2*x**2 + 3*x\n",
    "\n",
    "# 微分的数值计算\n",
    "# Numerical calculation of derivative\n",
    "x_numpy = np.array([2.0])\n",
    "h = 1e-7\n",
    "\n",
    "def numerical_derivative(f, x, h):\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "df_dx_numpy_manual = numerical_derivative(f, x_numpy, h)\n",
    "\n",
    "print(\"Numerical Derivative:\")\n",
    "print(f\"df/dx at x = {x_numpy[0]} is {df_dx_numpy_manual[0]}\")\n",
    "\n",
    "# 导数的解析计算\n",
    "# Analytical calculation of derivative\n",
    "def df(x):\n",
    "    return 3*x**2 + 4*x + 3\n",
    "\n",
    "x_theory = 2.0\n",
    "print(\"Theoretical Derivative:\")\n",
    "print(f\"df/dx at x = {x_theory} is {df(x_theory)}\")\n",
    "\n",
    "# PyTorch自动微分\n",
    "# PyTorch automatic differentiation\n",
    "x_torch = torch.tensor([2.0], requires_grad=True)\n",
    "y_torch = f(x_torch)\n",
    "\n",
    "dy_dx = torch.autograd.grad(y_torch, x_torch, grad_outputs=torch.ones_like(y_torch),\n",
    "                                create_graph=True)[0]\n",
    "print(\"PyTorch Automatic Derivative:\")\n",
    "print(f\"df/dx at x = {x_torch.item()} is {dy_dx.item()}\")"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 定义函数\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# define function\u001B[39;00m\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\__init__.py:2475\u001B[0m\n\u001B[0;32m   2471\u001B[0m     torch_module_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;18m__name__\u001B[39m, device_type])\n\u001B[0;32m   2472\u001B[0m     sys\u001B[38;5;241m.\u001B[39mmodules[torch_module_name] \u001B[38;5;241m=\u001B[39m module\n\u001B[1;32m-> 2475\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m   2476\u001B[0m     export \u001B[38;5;28;01mas\u001B[39;00m export,\n\u001B[0;32m   2477\u001B[0m     func \u001B[38;5;28;01mas\u001B[39;00m func,\n\u001B[0;32m   2478\u001B[0m     library \u001B[38;5;28;01mas\u001B[39;00m library,\n\u001B[0;32m   2479\u001B[0m     return_types \u001B[38;5;28;01mas\u001B[39;00m return_types,\n\u001B[0;32m   2480\u001B[0m )\n\u001B[0;32m   2481\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cond \u001B[38;5;28;01mas\u001B[39;00m cond, while_loop \u001B[38;5;28;01mas\u001B[39;00m while_loop\n\u001B[0;32m   2482\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\export\\__init__.py:64\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msymbolic_shapes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StrictMinMaxConstraint\n\u001B[0;32m     44\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConstraint\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDim\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnflattenedModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     61\u001B[0m ]\n\u001B[1;32m---> 64\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdynamic_shapes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Constraint, Dim, dims, ShapesCollection\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_signature\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExportBackwardSignature, ExportGraphSignature\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     _get_node_type,\n\u001B[0;32m     13\u001B[0m     BUILTIN_TYPES,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     tree_map_with_path,\n\u001B[0;32m     21\u001B[0m )\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Symbol\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\export\\exported_program.py:26\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcontextlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m contextmanager\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     13\u001B[0m     Any,\n\u001B[0;32m     14\u001B[0m     Callable,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m     Union,\n\u001B[0;32m     24\u001B[0m )\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograd_not_implemented\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_library\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfake_class_registry\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FakeScriptObject\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m first_call_function_nn_module_stack\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcond\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cond\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflex_attention\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      3\u001B[0m     flex_attention,\n\u001B[0;32m      4\u001B[0m     flex_attention_backward,\n\u001B[0;32m      5\u001B[0m )\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhints_wrap\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hints_wrapper\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_subclasses\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional_tensor\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DispatchKey\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01minductor_config\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _functionalization_reapply_views_tls \u001B[38;5;28;01mas\u001B[39;00m _reapply_views\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\_inductor\\config.py:44\u001B[0m\n\u001B[0;32m     40\u001B[0m verbose_progress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# use fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     43\u001B[0m fx_graph_cache \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m---> 44\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTORCHINDUCTOR_FX_GRAPH_CACHE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_fbcode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     45\u001B[0m )\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# use remote fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# False: Disables the cache\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# True: Enables the cache\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001B[39;00m\n\u001B[0;32m     51\u001B[0m fx_graph_remote_cache: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m fx_graph_remote_cache_default()\n",
      "File \u001B[1;32mD:\\PycharmProjects\\AI4S\\.venv\\lib\\site-packages\\torch\\_inductor\\config.py:9\u001B[0m, in \u001B[0;36mis_fbcode\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_fbcode\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mversion\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgit_version\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
