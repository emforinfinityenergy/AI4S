{
 "cells": [
  {
   "cell_type": "code",
   "id": "95ecd322d8cec521",
   "metadata": {},
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    # 读取CSV文件\n",
    "    # read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 获取时间t, x位置和y位置，并转换为Tensor，同时确保数据类型为torch.float32\n",
    "    # Retrieve time t, x, y, and convert them to Tensors, ensuring that the data type is torch.float32\n",
    "    t_obs = torch.tensor(df['Time'].values, dtype=torch.float64).view(-1, 1)\n",
    "    x_obs = torch.tensor(df['X'].values, dtype=torch.float64).view(-1, 1)\n",
    "    y_obs = torch.tensor(df['Y'].values, dtype=torch.float64).view(-1, 1)\n",
    "    t_start = t_obs[0].detach().numpy().item()  # 训练集数据和测试集数据的时间都是从0开始的\n",
    "    t_end = t_obs[-1].detach().numpy().item()\n",
    "\n",
    "    return t_start, t_end, t_obs, x_obs, y_obs\n",
    "\n",
    "\n",
    "# 定义重力加速度\n",
    "# define g\n",
    "g = 9.8\n",
    "\n",
    "nodes = 32"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PointData(Dataset):\n",
    "    def __init__(self, t_seq, p_seq):\n",
    "        self.t_seq = t_seq\n",
    "        self.p_seq = p_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.t_seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.t_seq[idx], self.p_seq[idx]"
   ],
   "id": "4c6179c3ff6f401b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# 定义神经网络，输入为时间t，输出为轨迹信息x, y坐标以及阻力参数k。\n",
    "# 你可以采用别的定义方法，这里只是给出了一种可行的方式\n",
    "# Define the neural network, with input as time t , and output as trajectory information including  x  and  y  coordinates, as well as the drag parameter k .\n",
    "# You can use a different method; this is just one possible approach.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 32, dtype=torch.float64), nn.Tanh(),\n",
    "            nn.Linear(32, 64, dtype=torch.float64), nn.Tanh(),\n",
    "            # nn.Linear(32, 32), nn.Tanh(),\n",
    "            nn.Linear(64, 2, dtype=torch.float64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "id": "bd551a89d9d1fb04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train(loader: DataLoader) -> nn.Module:\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    net = Net()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    NUM_EPOCHS = 1000\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for t, p in loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(t), p)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # if epoch % 50 == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         loss = criterion(net(t_seq), p_seq)\n",
    "        #         print(f\"Epoch {epoch}, loss = {loss}\")\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def calculate(data_path: str):\n",
    "    # Process the data\n",
    "    t_s, t_e, t_seq, x_seq, y_seq = load_data(data_path)\n",
    "    p_seq = torch.tensor(torch.zeros([len(t_seq), 2]), dtype=torch.float64)\n",
    "    for i in range(len(t_seq)):\n",
    "        p_seq[i] = torch.tensor([x_seq[i], y_seq[i]], dtype=torch.float64)\n",
    "    dataset = PointData(t_seq, p_seq)\n",
    "    loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    net = train(loader)\n",
    "\n",
    "    sx = 0\n",
    "    sy = 0\n",
    "    sm = 0\n",
    "    cnt = 0\n",
    "    samples = np.linspace(t_s, t_e, 5000)\n",
    "    for i in range(5000):\n",
    "        time_tensor = torch.tensor([samples[i]], dtype=torch.float64, requires_grad=True)\n",
    "        op = net(time_tensor)\n",
    "        # print(op)\n",
    "\n",
    "        dy_dt = torch.autograd.grad(op[1], time_tensor, grad_outputs=torch.ones_like(op[1]),\n",
    "                                    create_graph=True)[0]\n",
    "        d2y_dt2 = torch.autograd.grad(dy_dt, time_tensor, grad_outputs=torch.ones_like(dy_dt),\n",
    "                                      create_graph=True)[0]\n",
    "        dx_dt = torch.autograd.grad(op[0], time_tensor, grad_outputs=torch.ones_like(op[1]),\n",
    "                                    create_graph=True)[0]\n",
    "        d2x_dt2 = torch.autograd.grad(dx_dt, time_tensor, grad_outputs=torch.ones_like(dy_dt),\n",
    "                                      create_graph=True)[0]\n",
    "\n",
    "        # if abs(dy_dt.item()) > 10 or abs(dx_dt.item()) > 10 or abs(d2y_dt2.item()) > 10 or abs(d2x_dt2.item()) > 10:\n",
    "        #     continue\n",
    "        # print(\"dx\", dx_dt)\n",
    "        # print(\"dy\", dy_dt)\n",
    "        # print(d2x_dt2, d2y_dt2)\n",
    "        v_gs = math.sqrt(dx_dt ** 2 + dy_dt ** 2)\n",
    "        kx = d2x_dt2 / (dx_dt * v_gs)\n",
    "        ky = (d2y_dt2 + 9.8) / (dy_dt * v_gs)\n",
    "        # print(kx, ky)\n",
    "        sx += kx.item()\n",
    "        sy += ky.item()\n",
    "        sm += (kx.item() + ky.item()) / 2\n",
    "        # print((kx + ky) / 2)\n",
    "        cnt += 1\n",
    "\n",
    "    k = sx / cnt * -1\n",
    "\n",
    "    eva_samples = np.linspace(t_s, t_e, 100000)\n",
    "    max_height = -1\n",
    "    max_point = None\n",
    "    max_v = None\n",
    "    for sample in eva_samples:\n",
    "        sample_tensor = torch.tensor([sample], dtype=torch.float64, requires_grad=True)\n",
    "        pred = net(sample_tensor)\n",
    "        if pred[1].item() > max_height:\n",
    "            max_point = (pred[0].item(), pred[1].item())\n",
    "            dx_dt = torch.autograd.grad(pred[0], sample_tensor, grad_outputs=torch.ones_like(pred[1]),\n",
    "                                        create_graph=True)[0]\n",
    "            dy_dt = torch.autograd.grad(pred[1], sample_tensor, grad_outputs=torch.ones_like(pred[1]),\n",
    "                                        create_graph=True)[0]\n",
    "            max_v = (dx_dt, dy_dt)\n",
    "            max_height = pred[1].item()\n",
    "\n",
    "\n",
    "    end_tensor = torch.tensor([t_e], dtype=torch.float64, requires_grad=True)\n",
    "    pred = net(end_tensor)\n",
    "    dx_dt = torch.autograd.grad(pred[0], end_tensor, grad_outputs=torch.ones_like(pred[1]),\n",
    "                                create_graph=True)[0]\n",
    "    dy_dt = torch.autograd.grad(pred[1], end_tensor, grad_outputs=torch.ones_like(pred[1]),\n",
    "                                create_graph=True)[0]\n",
    "    slope = dy_dt / dx_dt\n",
    "    offset = pred[1].item() - slope * pred[0].item()\n",
    "    s = -1 * offset / slope\n",
    "\n",
    "    return k, max_height, s.item()"
   ],
   "id": "c35a05a8eb3e92a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "def calculate_parameters(data_path, submission_path):\n",
    "    k_pred, height_max, range_max = calculate(data_path)\n",
    "    with open(submission_path, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['k', 'height_max', 'range_max'])\n",
    "        writer.writerow([k_pred, height_max, range_max])"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#---------提交范例-------#\n",
    "#---------Submission example-------#\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "#导入训练集数据\n",
    "# import training data\n",
    "\n",
    "TRAIN_PATH = \"/bohr/train-g6oc/v1/\"\n",
    "calculate_parameters(data_path=TRAIN_PATH + \"projectile_train.csv\", submission_path=\"submission_train.csv\")  #求解训练集方程"
   ],
   "id": "24d3162bd6642613",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 导入测试集数据\n",
    "#“DATA_PATH”是测试集加密后的环境变量，按照如下方式可以在提交后，系统评分时访问测试集，但是选手无法直接下载\n",
    "# import test data\n",
    "#\"DATA_PATH\" is an encrypted environment variable for the test set. It can be accessed by the system for scoring after submission, but contestants cannot directly download it.\n",
    "\n",
    "if os.environ.get('DATA_PATH'):\n",
    "    DATA_PATH = os.environ.get(\"DATA_PATH\") + \"/\"\n",
    "else:\n",
    "    #Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\n",
    "    #During the execution of the Baseline, since it is unable to read the test set, this error message will appear, which is a normal phenomenon\n",
    "    print(\n",
    "        \"During the execution of the Baseline, since it is unable to read the test set, this error message will appear, which is a normal phenomenon.\")\n",
    "calculate_parameters(data_path=DATA_PATH + \"projectile_testA.csv\",\n",
    "                     submission_path=\"submission_testA.csv\")  #求解Public测试集方程\n",
    "calculate_parameters(data_path=DATA_PATH + \"projectile_testB.csv\",\n",
    "                     submission_path=\"submission_testB.csv\")  #求解Private测试集方程"
   ],
   "id": "678135bdd396f557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 定义要打包的文件和压缩文件名\n",
    "files_to_zip = ['submission_testA.csv', 'submission_testB.csv']\n",
    "zip_filename = 'submission.zip'\n",
    "\n",
    "# 创建一个 zip 文件\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    for file in files_to_zip:\n",
    "        # 将文件添加到 zip 文件中\n",
    "        zipf.write(file, os.path.basename(file))\n",
    "\n",
    "print(f'{zip_filename} 创建成功!')"
   ],
   "id": "57c0c422ed677355",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
